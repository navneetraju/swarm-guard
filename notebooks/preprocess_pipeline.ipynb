{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import torch\n",
    "import requests\n",
    "from PIL import Image\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import RobertaTokenizer, ViTFeatureExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetClass(torch.utils.data.Dataset):\n",
    "    def __inti__(self,path,tokenizer,feature_extractor,img_dir):\n",
    "        '''\n",
    "        Args:\n",
    "        path (str): path to trees json files\n",
    "        tokenizer: Text, currenlty use RobertaTokenizer <= Change Later\n",
    "        feature_extractor: Image, currently use ViTFeatureExtractor <= Change Later\n",
    "        img_dir (str): directory to images \n",
    "\n",
    "        Note: Currenlty, I'm downloading images from URL and saving folder.\n",
    "        Later update it..\n",
    "\n",
    "        '''\n",
    "        self.path = path\n",
    "        self.tokenizer = tokenizer\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.img_dir = img_dir\n",
    "\n",
    "        os.makedirs(self.img_dir,exist_ok=True)\n",
    "        self.data = self.load_dataset()\n",
    "\n",
    "        def extract_url(self,tweet_text):\n",
    "            url_pattern = re.compile(r'https?://\\S+') # URL pattern\n",
    "            return url_pattern.findall(tweet_text)\n",
    "        \n",
    "        def download_image(self,url,filename):\n",
    "            ''' I'm trying to download image from URL and save it in folder '''\n",
    "            try:\n",
    "                response = requests.get(url,timeout=5) \n",
    "                if response.status_code == 200:\n",
    "                    filepath = os.path.join(self.img_dir,filename)\n",
    "                    with open(filepath,'wb') as f: # write binary\n",
    "                        f.write(response.content)\n",
    "                    return filepath\n",
    "            except Exception as e:\n",
    "                print(f\"Error downloading image {url}: {e}\")\n",
    "            return None\n",
    "        \n",
    "        def load_dataset(self):\n",
    "            ''' Load dataset from json files '''\n",
    "            processed_data = []\n",
    "            \n",
    "            for filename in os.listdir(self.dataset_path):\n",
    "                if filename.endswith('.json'):\n",
    "                    filepath = os.path.join(self.dataset_path, filename)\n",
    "                    \n",
    "                    with open(filepath, 'r') as f:\n",
    "                        data = json.load(f)\n",
    "                    \n",
    "                    # I'm trying to extract label, Needed?\n",
    "                    label = 1 if data['label'] == 'real' else 0\n",
    "                    \n",
    "                    # Graph\n",
    "                    node_features = [] # Like followers_count, following_count, verified status\n",
    "                    node_id_map = {}  # Map node IDs to indices for edge construction (Like source-target pairs)\n",
    "                    \n",
    "                    text_inputs = []\n",
    "                    image_inputs = []\n",
    "                    \n",
    "                    for idx, node in enumerate(data['nodes']):\n",
    "                        # Map node ID to index for edge construction later\n",
    "                        node_id_map[node['id']] = idx\n",
    "                        \n",
    "                        # Text processing\n",
    "                        tweet_text = node['tweet_text']\n",
    "                        text_input = self.tokenizer(\n",
    "                            tweet_text,\n",
    "                            padding=True,\n",
    "                            truncation=True,\n",
    "                            return_tensors='pt'\n",
    "                        )\n",
    "                        text_inputs.append(text_input)\n",
    "                        \n",
    "                        # Image processing\n",
    "                        image_urls = self.extract_urls(tweet_text)\n",
    "                        image_path = None\n",
    "                        if image_urls:\n",
    "                            image_filename = f\"{node['id']}.jpg\"\n",
    "                            image_path = self.download_image(image_urls[0], image_filename)\n",
    "                        \n",
    "                        if image_path:\n",
    "                            image_input = self.feature_extractor(\n",
    "                                Image.open(image_path),\n",
    "                                return_tensors='pt'\n",
    "                            )\n",
    "                            image_inputs.append(image_input)\n",
    "                        else:\n",
    "                            # Fallback: Just use a random tensor if no image available\n",
    "                            random_image_tensor = {'pixel_values': torch.randn(1, 3, 224, 224)}\n",
    "                            image_inputs.append(random_image_tensor)\n",
    "                        \n",
    "                        features = torch.tensor([\n",
    "                            node['followers_count'],\n",
    "                            node['following_count'],\n",
    "                            node['verified']\n",
    "                        ], dtype=torch.float)\n",
    "                        \n",
    "                        node_features.append(features)\n",
    "                    \n",
    "                    # Process edges using source-target pairs from JSON's \"edges\" key\n",
    "                    edge_index = []\n",
    "                    for edge in data['edges']:\n",
    "                        source_idx = node_id_map.get(edge['source'])\n",
    "                        target_idx = node_id_map.get(edge['target'])\n",
    "                        \n",
    "                        if source_idx is not None and target_idx is not None:\n",
    "                            edge_index.append((source_idx, target_idx))\n",
    "                    \n",
    "                    # Convert edge list to PyTorch tensor(edge_index)\n",
    "                    # Stored column-wise (i.e., first row contains source nodes, second row contains target nodes)\n",
    "                    edge_index_tensor = torch.tensor(edge_index).t().contiguous()  # Convert to PyTorch tensor\n",
    "                    \n",
    "                    # Create a PyTorch Geometric Data object for graph representation\n",
    "                    # (See https://pytorch-geometric.readthedocs.io/en/latest/notes/introduction.html#data-handling-of-graphs)\n",
    "\n",
    "                    graph_data = Data(\n",
    "                        x=torch.stack(node_features),  # Node features matrix [num_nodes x num_features]\n",
    "                        edge_index=edge_index_tensor  # Edge index [2 x num_edges]\n",
    "                    )\n",
    "                    \n",
    "                    # I'm currenlty returning graph, text_inputs, image_inputs, label\n",
    "                    processed_entry = {\n",
    "                        'graph': graph_data,\n",
    "                        'text_inputs': text_inputs,\n",
    "                        'image_inputs': image_inputs,\n",
    "                        'label': label,\n",
    "                    }\n",
    "                    \n",
    "                    processed_data.append(processed_entry)\n",
    "            \n",
    "            return processed_data\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.data)\n",
    "        \n",
    "        def __getitem__(self, idx):\n",
    "            return self.data[idx]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    - batch (list): Batch of processed entries.\n",
    "    graph: A PyTorch Geometric Data object representing a graph.\n",
    "    text_inputs: Tokenized text inputs.\n",
    "    image_inputs: pixel_values\n",
    "    label: The label for the sample.\n",
    "\n",
    "    \"\"\"\n",
    "    graphs_batch = [item['graph'] for item in batch]\n",
    "    labels_batch = torch.tensor([item['label'] for item in batch])\n",
    "    \n",
    "    text_batch_input_ids = torch.nn.utils.rnn.pad_sequence(\n",
    "        [t['input_ids'].squeeze() for item in batch for t in item['text_inputs']],\n",
    "        batch_first=True\n",
    "    )\n",
    "    # Attention mask and token type IDs are the same for all text inputs\n",
    "    text_batch_attention_mask = torch.nn.utils.rnn.pad_sequence(\n",
    "        [t['attention_mask'].squeeze() for item in batch for t in item['text_inputs']],\n",
    "        batch_first=True\n",
    "    )\n",
    "    \n",
    "    text_batch = {\n",
    "        'input_ids': text_batch_input_ids,\n",
    "        'attention_mask': text_batch_attention_mask,\n",
    "    }\n",
    "    \n",
    "    # Stack image pixel values into a single tensor\n",
    "    image_batch_pixel_values = torch.stack(\n",
    "        [i['pixel_values'].squeeze() for item in batch for i in item['image_inputs']]\n",
    "    )\n",
    "    \n",
    "    image_batch = {\n",
    "        'pixel_values': image_batch_pixel_values,\n",
    "    }\n",
    "    \n",
    "    return {\n",
    "        'graphs': graphs_batch,\n",
    "        'text_batch': text_batch,\n",
    "        'image_batch': image_batch,\n",
    "        'labels': labels_batch,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
